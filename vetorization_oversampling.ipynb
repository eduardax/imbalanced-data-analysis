{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eduardax/imbalanced-data-analysis/blob/main/vetorization_oversampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uc5FVMlWYgaM",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Instalando e Importando\n",
        "!pip install pandas-profiling\n",
        "!pip install imbalanced-learn\n",
        "import imblearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.datasets import make_classification\n",
        "import os\n",
        "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, RandomOverSampler, ADASYN\n",
        "import warnings\n",
        "import traceback\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from imblearn.pipeline import make_pipeline\n",
        "import matplotlib\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn import FunctionSampler  # to use a idendity sampler\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "print(__doc__)\n",
        "\n",
        "sns.set_context(\"poster\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYI98TUTYy8w"
      },
      "outputs": [],
      "source": [
        "# Montando a partição do Google Drive para acessar os arquivos\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9N1rs-hYzVH"
      },
      "outputs": [],
      "source": [
        "# Função para carregar dados\n",
        "def load_data(file_path):\n",
        "    df = pd.read_csv(file_path, sep=';', encoding='utf-8', usecols=['label', 'processed_abstract_text'])\n",
        "    df['label'] = df['label'] - 1  # Ajusta as labels para começar de 0\n",
        "    return df\n",
        "\n",
        "arquivo = '/content/drive/MyDrive/Colab Notebooks/tcc_pro/tcc/original_and_preprocessed.csv'\n",
        "\n",
        "dataset = load_data(arquivo)\n",
        "dataset = pd.DataFrame(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Extrair as informações do CSV\n",
        "labels = dataset['label'].values + 1\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(16, 7))\n",
        "idx, c = np.unique(labels, return_counts=True)\n",
        "\n",
        "# Definir as cores para cada ODS\n",
        "ods_colors = {\n",
        "    1: \"#E5243B\",\n",
        "    2: \"#F4F5F6\",\n",
        "    3: \"#4C9F38\",\n",
        "    4: \"#C5192D\",\n",
        "    5: \"#FF3A21\",\n",
        "    6: \"#26BDE2\",\n",
        "    7: \"#FCC30B\",\n",
        "    8: \"#A21942\",\n",
        "    9: \"#FD6925\",\n",
        "    10: \"#DD1367\",\n",
        "    11: \"#FD9D24\",\n",
        "    12: \"#BF8B2E\",\n",
        "    13: \"#3F7E44\",\n",
        "    14: \"#0A97D9\",\n",
        "    15: \"#56C02B\",\n",
        "    16: \"#00689D\",\n",
        "    17: \"#19486A\"\n",
        "}\n",
        "\n",
        "# Criar a lista de cores baseado nos labels\n",
        "colors = [ods_colors.get(label, \"#fffff\") for label in idx]  # Azul padrão para valores não especificados\n",
        "\n",
        "# Plotar o gráfico de barras\n",
        "sns.barplot(x=idx, y=c, ax=ax, palette=colors)\n",
        "\n",
        "# Adicionar valores no topo de cada barra com tamanho de fonte ajustado\n",
        "for i in range(len(idx)):\n",
        "    ax.text(i, c[i], str(c[i]), ha='center', va='bottom', fontsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# Salvar a imagem plotada em um diretório específico\n",
        "output_directory = '/content/drive/MyDrive/Colab Notebooks/tcc_pro/tcc/'\n",
        "output_filename = 'class_distribution_BEFORE_oversampling.png'\n",
        "output_path = f\"{output_directory}/{output_filename}\"\n",
        "plt.savefig(output_path)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Axhd1L_pHcVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = dataset['processed_abstract_text']\n",
        "y = dataset['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "num_train_samples = len(X_train)\n",
        "num_train_labels = len(y_train)\n",
        "num_test_samples = len(X_test)\n",
        "num_test_labels = len(y_test)\n",
        "\n",
        "print(f\"Quantidade de exemplos em X_train: {num_train_samples}\")\n",
        "print(f\"Quantidade de rótulos em y_train: {num_train_labels}\")\n",
        "print(f\"Quantidade de exemplos em X_test: {num_test_samples}\")\n",
        "print(f\"Quantidade de rótulos em y_test: {num_test_labels}\")"
      ],
      "metadata": {
        "id": "Fw-aWI3K4QJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar DataFrame com X_sm como uma coluna única\n",
        "df_test = pd.DataFrame({'processed_abstract_text': X_test, 'label': y_test})\n",
        "df = pd.DataFrame({'processed_abstract_text': X_train, 'label': y_train})\n",
        "\n",
        "# Salvar em um arquivo CSV\n",
        "df_test.to_csv('/content/drive/MyDrive/Colab Notebooks/tcc_pro/tcc/df_test.csv', index=False)"
      ],
      "metadata": {
        "id": "xYAZSy1NJaET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJdVLlBNYzca"
      },
      "outputs": [],
      "source": [
        "#Funcao para coletar até 400 samples de cada label\n",
        "def load_and_select_data(column_a, column_b, num_samples_per_class=300):\n",
        "    # Criar um DataFrame vazio para armazenar os dados selecionados\n",
        "    selected_data = pd.DataFrame(columns=[column_a, column_b])\n",
        "\n",
        "    # Pegar os valores únicos da coluna de classificação\n",
        "    unique_classes = df_resampled[column_b].unique()\n",
        "\n",
        "    # Selecionar 400 valores da coluna A para cada classe na coluna B\n",
        "    for cls in unique_classes:\n",
        "        class_subset = df_resampled[df_resampled[column_b] == cls]\n",
        "        sampled_subset = class_subset.sample(n=min(num_samples_per_class, len(class_subset)), random_state=42)\n",
        "        selected_data = pd.concat([selected_data, sampled_subset])\n",
        "\n",
        "    return selected_data\n",
        "# Exibir os dados selecionados\n",
        "# print(selected_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fv_vectorizer = CountVectorizer(min_df=1)\n",
        "X_fv = fv_vectorizer.fit_transform(df['processed_abstract_text']).toarray()\n",
        "\n",
        "tokens = fv_vectorizer.get_feature_names_out() #Aqui pega os tokens\n",
        "tokens"
      ],
      "metadata": {
        "id": "c5LZRqVJ7msc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKtv7-A7YzhU"
      },
      "outputs": [],
      "source": [
        "# Contar os valores de cada rótulo\n",
        "value_counts_selected_data = df['label'].value_counts()\n",
        "print(\"\\nContagem de valores por rótulo:\")\n",
        "print(value_counts_selected_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = fv_vectorizer.get_feature_names_out() #Aqui pega os tokens\n",
        "tokens"
      ],
      "metadata": {
        "id": "q5JVft5_fVqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_fv\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(df['label'])"
      ],
      "metadata": {
        "id": "kwm9ACsSpSev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Resampled dataset shape %s' % Counter(y_train))"
      ],
      "metadata": {
        "id": "TAGVx3aryCls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decodeMatrix(matrix, tokens, labels):\n",
        "    documents = []\n",
        "    documents_with_tokens_and_labels = []  # Lista para armazenar documentos com tokens e labels correspondentes\n",
        "\n",
        "    #Colocar retorno para ser dataframe do jeito que tu quiser (Que o BERT no caso)\n",
        "    for row, label in zip(matrix, labels):\n",
        "        selected_tokens = []\n",
        "        for index, value in enumerate(row):\n",
        "            if value != 0:  # Aqui pode adicionar um for pra add a quantidade de palavras de acordo com o numero do Saco de Palavras\n",
        "                selected_tokens.append(tokens[index])\n",
        "\n",
        "        # Concatenar os tokens selecionados para formar o documento\n",
        "        document = ' '.join(selected_tokens)\n",
        "\n",
        "        # Armazenar o documento, seus tokens correspondentes e a label\n",
        "        documents.append(document)\n",
        "        documents_with_tokens_and_labels.append({\n",
        "            'new_text': document,\n",
        "#            'selected_tokens': selected_tokens,\n",
        "            'label': label\n",
        "        })\n",
        "\n",
        "    return documents, documents_with_tokens_and_labels"
      ],
      "metadata": {
        "id": "TS2WOBIIOYv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RandomOversampler"
      ],
      "metadata": {
        "id": "Xw6YSnUwZmTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ros = RandomOverSampler(random_state=42)\n",
        "X_res, y_res = ros.fit_resample(X_train.values.reshape(-1, 1), y_train)\n",
        "print('Resampled dataset shape %s' % Counter(y_res))\n",
        "\n",
        "# Converter X_sm para uma lista (coluna única)\n",
        "X_res_list = X_res.tolist()\n",
        "\n",
        "# Criar DataFrame com X_sm como uma coluna única\n",
        "df_resampled = pd.DataFrame({'processed_abstract_text': X_res_list, 'label': y_res})\n",
        "\n",
        "# Salvar em um arquivo CSV\n",
        "df_resampled.to_csv('/content/drive/MyDrive/Colab Notebooks/tcc_pro/tcc/random/dados_RO.csv', index=False)\n",
        "\n",
        "# Contar o número de exemplos por classe após o resample\n",
        "print('Resampled dataset shape %s' % Counter(y_res))"
      ],
      "metadata": {
        "id": "o5BKGf9EEB2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ostrezentos = load_and_select_data('processed_abstract_text', 'label')"
      ],
      "metadata": {
        "id": "lrhxtisdez_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Resampled dataset shape %s' % Counter(ostrezentos['label']))"
      ],
      "metadata": {
        "id": "BS0_WtIUfRAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar um DataFrame com os documentos, tokens e labels correspondentes\n",
        "df_with_tokens_and_labels = pd.DataFrame(ostrezentos)\n",
        "\n",
        "df_with_tokens_and_labels.head()\n",
        "\n",
        "# Salvar em um arquivo CSV\n",
        "df_with_tokens_and_labels.to_csv('/content/drive/MyDrive/Colab Notebooks/tcc_pro/tcc/smote/train_SMOTE_after_decode.csv', index=False)\n",
        "\n",
        "# Contar o número de exemplos por classe após o resample\n",
        "print('Resampled dataset shape %s' % Counter(df_with_tokens_and_labels['label']))"
      ],
      "metadata": {
        "id": "gkXAWzu1MDGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SMOTE"
      ],
      "metadata": {
        "id": "OyCedOem0HPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicação do SMOTE com um número adequado de vizinhos\n",
        "k_neighbors = 1\n",
        "\n",
        "smote = SMOTE(random_state=42, k_neighbors=k_neighbors)\n",
        "X_sm, y_sm = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Converter X_sm para uma lista (coluna única)\n",
        "X_sm_list = X_sm.tolist()\n",
        "\n",
        "# Criar DataFrame com X_sm como uma coluna única\n",
        "df_resampled = pd.DataFrame({'processed_abstract_text': X_sm_list, 'label': y_sm})\n",
        "\n",
        "# Salvar em um arquivo CSV\n",
        "df_resampled.to_csv('/content/drive/MyDrive/Colab Notebooks/tcc_pro/tcc/smote/dados_SMOTE.csv', index=False)\n",
        "\n",
        "# Contar o número de exemplos por classe após o resample\n",
        "print('Resampled dataset shape %s' % Counter(y_sm))"
      ],
      "metadata": {
        "id": "MPlVqUI4pH6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resampled.head()"
      ],
      "metadata": {
        "id": "hZMbJYwLx3DX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decodificar a matriz com tokens e labels\n",
        "documents, documents_with_tokens_and_labels = decodeMatrix(df_resampled['processed_abstract_text'], tokens, y_sm)\n",
        "\n",
        "# Criar um DataFrame com os documentos, tokens e labels correspondentes\n",
        "df_with_tokens_and_labels = pd.DataFrame(documents_with_tokens_and_labels)\n",
        "\n",
        "df_with_tokens_and_labels.head()\n",
        "\n",
        "# Salvar em um arquivo CSV\n",
        "df_with_tokens_and_labels.to_csv('/content/drive/MyDrive/Colab Notebooks/tcc_pro/tcc/smote/train_SMOTE_after_decode.csv', index=False)\n",
        "\n",
        "# Contar o número de exemplos por classe após o resample\n",
        "print('Resampled dataset shape %s' % Counter(df_with_tokens_and_labels['label']))"
      ],
      "metadata": {
        "id": "L3OIVdhkl3RO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, x in enumerate(df_with_tokens_and_labels['new_text']):\n",
        "  if not isinstance(x, str): print(f'nan in {i} : {x}')"
      ],
      "metadata": {
        "id": "gf6xeXBAFxkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Funcao para coletar até 400 samples de cada label\n",
        "def load_and_select_data_sm(column_a, column_b, num_samples_per_class=300):\n",
        "    # Criar um DataFrame vazio para armazenar os dados selecionados\n",
        "    selected_data = pd.DataFrame(columns=[column_a, column_b])\n",
        "\n",
        "    # Pegar os valores únicos da coluna de classificação\n",
        "    unique_classes = df_with_tokens_and_labels[column_b].unique()\n",
        "\n",
        "    # Selecionar 400 valores da coluna A para cada classe na coluna B\n",
        "    for cls in unique_classes:\n",
        "        class_subset = df_with_tokens_and_labels[df_with_tokens_and_labels[column_b] == cls]\n",
        "        sampled_subset = class_subset.sample(n=min(num_samples_per_class, len(class_subset)), random_state=42)\n",
        "        selected_data = pd.concat([selected_data, sampled_subset])\n",
        "\n",
        "    return selected_data"
      ],
      "metadata": {
        "id": "Xcd8C_RpIk4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_with_tokens_and_labels = load_and_select_data_sm('new_text', 'label')\n",
        "\n",
        "# Salvar em um arquivo CSV\n",
        "df_with_tokens_and_labels.to_csv('/content/drive/MyDrive/Colab Notebooks/tcc_pro/tcc/bsmote/train_BSMOTE_after_decode.csv', index=False)\n",
        "\n",
        "# Contar o número de exemplos por classe após o resample\n",
        "print('Resampled dataset shape %s' % Counter(df_with_tokens_and_labels['label']))"
      ],
      "metadata": {
        "id": "7tDgmAbHIyyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_with_tokens_and_labels.head()"
      ],
      "metadata": {
        "id": "NA9urauJ20q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Borderline-SMOTE"
      ],
      "metadata": {
        "id": "6I4hCe1Sz_Wn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoTxoOmsY4Ka"
      },
      "outputs": [],
      "source": [
        "Bsm = BorderlineSMOTE(random_state=42,  k_neighbors=k_neighbors)\n",
        "X_res_Bsm, y_res_Bsm = Bsm.fit_resample(X_train, y_train)\n",
        "\n",
        "# Converter X_sm para uma lista (coluna única)\n",
        "X_bsm_list = X_res_Bsm.tolist()\n",
        "\n",
        "# Criar DataFrame com X_sm como uma coluna única\n",
        "df_resampled_bsm = pd.DataFrame({'processed_abstract_text': X_bsm_list, 'label': y_res_Bsm})\n",
        "\n",
        "# Salvar em um arquivo CSV\n",
        "df_resampled_bsm.to_csv('/content/drive/MyDrive/Colab Notebooks/tcc_pro/tcc/bsmote/dados_BSMOTE_after_oversampling.csv', index=False)\n",
        "\n",
        "# Contar o número de exemplos por classe após o resample\n",
        "print('Resampled dataset shape %s' % Counter(y_res_Bsm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgJAHu0yY4Wr"
      },
      "outputs": [],
      "source": [
        "df_resampled_bsm.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decodificar a matriz com tokens e labels\n",
        "documentsBSM, documents_with_tokens_and_labelsBSM = decodeMatrix(df_resampled_bsm['processed_abstract_text'], tokens, y_res_Bsm)\n",
        "\n",
        "# Criar um DataFrame com os documentos, tokens e labels correspondentes\n",
        "df_with_tokens_and_labelsBSM = pd.DataFrame(documents_with_tokens_and_labelsBSM)\n",
        "\n",
        "df_with_tokens_and_labelsBSM.head()"
      ],
      "metadata": {
        "id": "fNJcbUEf1U1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, x in enumerate(df_with_tokens_and_labelsBSM['new_text']):\n",
        "  if not isinstance(x, str): print(f'nan in {i} : {x}')"
      ],
      "metadata": {
        "id": "tCHJiMkUGZw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Funcao para coletar até 400 samples de cada label\n",
        "def load_and_select_data_ada(column_a, column_b, num_samples_per_class=300):\n",
        "    # Criar um DataFrame vazio para armazenar os dados selecionados\n",
        "    selected_data = pd.DataFrame(columns=[column_a, column_b])\n",
        "\n",
        "    # Pegar os valores únicos da coluna de classificação\n",
        "    unique_classes = df_with_tokens_and_labelsBSM[column_b].unique()\n",
        "\n",
        "    # Selecionar 400 valores da coluna A para cada classe na coluna B\n",
        "    for cls in unique_classes:\n",
        "        class_subset = df_with_tokens_and_labelsBSM[df_with_tokens_and_labelsBSM[column_b] == cls]\n",
        "        sampled_subset = class_subset.sample(n=min(num_samples_per_class, len(class_subset)), random_state=42)\n",
        "        selected_data = pd.concat([selected_data, sampled_subset])\n",
        "\n",
        "    return selected_data"
      ],
      "metadata": {
        "id": "L7W4tBwoH-ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_with_tokens_and_labelsBSM = load_and_select_data_ada('new_text', 'label')\n",
        "\n",
        "# Salvar em um arquivo CSV\n",
        "df_with_tokens_and_labelsBSM.to_csv('/content/drive/MyDrive/Colab Notebooks/tcc_pro/tcc/bsmote/train_BSMOTE_after_decode.csv', index=False)\n",
        "\n",
        "# Contar o número de exemplos por classe após o resample\n",
        "print('Resampled dataset shape %s' % Counter(df_with_tokens_and_labelsBSM['label']))"
      ],
      "metadata": {
        "id": "uRHOCnUeICMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_with_tokens_and_labelsBSM.head()"
      ],
      "metadata": {
        "id": "jX-TrGJo2kdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ADASYN"
      ],
      "metadata": {
        "id": "UtKVJeF536g8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adasyn = ADASYN(random_state=42, n_neighbors=1)\n",
        "X_adasyn, y_adasyn = adasyn.fit_resample(X_train, y_train)\n",
        "\n",
        "# Converter X_sm para uma lista (coluna única)\n",
        "X_adasyn_list = X_adasyn.tolist()\n",
        "\n",
        "# Criar DataFrame com X_sm como uma coluna única\n",
        "df_resampled_adasyn = pd.DataFrame({'processed_abstract_text': X_adasyn_list, 'label': y_adasyn})\n",
        "\n",
        "# Salvar em um arquivo CSV\n",
        "df_resampled_adasyn.to_csv('/content/drive/MyDrive/Colab Notebooks/tcc_pro/tcc/adasyn/train_ADASYN_after_oversampling.csv', index=False)\n",
        "\n",
        "# Contar o número de exemplos por classe após o resample\n",
        "print('Resampled dataset shape %s' % Counter(y_adasyn))"
      ],
      "metadata": {
        "id": "Hf7FeXiP2wk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resampled_adasyn.head()"
      ],
      "metadata": {
        "id": "aVVls4oU3yj2",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decodificar a matriz com tokens e labels\n",
        "documentsADA, documents_with_tokens_and_labelsADA = decodeMatrix(df_resampled_adasyn['processed_abstract_text'], tokens, y_adasyn)\n",
        "\n",
        "# Criar um DataFrame com os documentos, tokens e labels correspondentes\n",
        "df_with_tokens_and_labelsADA_pre = pd.DataFrame(documents_with_tokens_and_labelsADA)\n",
        "\n",
        "df_with_tokens_and_labelsADA = load_and_select_data_ada('new_text', 'label')\n",
        "\n",
        "df_with_tokens_and_labelsADA.head()\n",
        "\n",
        "# Salvar em um arquivo CSV\n",
        "df_with_tokens_and_labelsADA.to_csv('/content/drive/MyDrive/Colab Notebooks/tcc_pro/tcc/adasyn/train_ADASYN_after_decode.csv', index=False)\n",
        "\n",
        "# Contar o número de exemplos por classe após o resample\n",
        "print('Resampled dataset shape %s' % Counter(df_with_tokens_and_labelsADA['label']))"
      ],
      "metadata": {
        "id": "HdKATF4O4E7q",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, x in enumerate(df_with_tokens_and_labelsADA['new_text']):\n",
        "  if not isinstance(x, str): print(f'nan in {i} : {x}')"
      ],
      "metadata": {
        "id": "00p54L1AHiTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_with_tokens_and_labelsADA.head()"
      ],
      "metadata": {
        "id": "_SSCNfLq4oDn",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP11OLcpeoR6WlHK8+jLWZF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}